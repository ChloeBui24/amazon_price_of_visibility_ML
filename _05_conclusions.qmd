# Conclusions
This project set out to answer the main question: What factors influence product ordering in Amazon’s Health & Baby Care search results? By combining exploratory analysis, engineered features, and a suite of predictive models, we found that while some product attributes are loosely associated with placement, such as star ratings, review volume, stock availability, and recent demand, the overall predictability of product order remains limited. This confirms our initial hypothesis that Amazon’s ranking algorithm is a complex “black box,” shaped by more than just product quality or consumer preferences.

Our regression analysis, beginning with linear and Lasso models, revealed that product features explain only a small portion of the variance in product_order. The best-performing linear model achieved an R² of just 0.19, and Lasso regression, while helpful in simplifying the feature set, did not significantly improve predictive performance. Notably, features like log_interaction (rating × review volume), last_month_rank, and log_brand_popularity emerged as consistently influential across models, suggesting that consumer engagement and historical demand play some role in product visibility.

The Random Forest classifier provided moderate improvement over linear methods in classifying page numbers, achieving a test accuracy of 41% and reinforcing the relative importance of similar features. Yet even this non-linear ensemble approach struggled to overcome the inherent noise and complexity of the data. 

These results point to a key insight: Amazon’s product ranking system for Health & Baby Care seems to rely on many hidden factors that we can’t observe directly. While we analyzed visible product features like ratings, reviews, price, and stock status, the low predictive power of our models suggests that other behind-the-scenes signals are driving placement, which might be advertising spend, whether a product uses Amazon’s fulfillment services, or engagement metrics Amazon doesn’t make public. This makes it difficult to fully understand how products are ranked, especially in a category where consumer trust and safety are critical.

Despite these challenges, our project demonstrates a practical way to study opaque ranking systems. By scraping publicly available data, carefully engineering features, and applying interpretable machine learning models, we were able to identify patterns, even if they weren’t strong enough to make highly accurate predictions. Importantly, we did find consistent signals that align with commercial popularity, such as product engagement and prior sales volume, reinforcing the idea that visibility is influenced by factors beyond just product quality.

This work also lays the groundwork for future research. One promising direction is to collect more types of data—like whether a product is sponsored, what keywords it ranks for, or how users interact with it. These could improve model performance and help reveal the full logic of the algorithm. Another path involves studying Amazon’s seller tools and advertising programs to better understand how sellers influence their own visibility. 

In short, we didn’t crack the full code of Amazon’s algorithm, but we took a meaningful step toward understanding it. Our results show that while public data can offer important clues, full transparency is still lacking, especially in product categories where rankings can affect real health decisions. If platforms like Amazon want to earn consumer trust, clearer explanations of how rankings are determined will be essential.